{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-15T08:40:08.850606Z","iopub.execute_input":"2022-04-15T08:40:08.850881Z","iopub.status.idle":"2022-04-15T08:40:08.865354Z","shell.execute_reply.started":"2022-04-15T08:40:08.850849Z","shell.execute_reply":"2022-04-15T08:40:08.864468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install d2l","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:08.951378Z","iopub.execute_input":"2022-04-15T08:40:08.951593Z","iopub.status.idle":"2022-04-15T08:40:16.725597Z","shell.execute_reply.started":"2022-04-15T08:40:08.951567Z","shell.execute_reply":"2022-04-15T08:40:16.724735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport torch\nimport torchvision\nfrom torch import nn\nfrom d2l import (\n    torch as d2l,\n)  # 把d2l中的torch包重新命名为d2l进行调用，有些方法被d2l的作者保存在了d2l的包中，并且用一个注释#@save指明了\n\nd2l.set_figsize([4, 4])  # d2l定义的一个设置图片大小的函数,可以输入一个列表手动控制大小如[5,6]\ncontent_img = d2l.Image.open(\"../input/imageshow/content.jpg\")  # 从当前目录导入内容图片\nprint(content_img)  # 图片格式\nd2l.plt.imshow(content_img)\n# 按照指定格式展示图片，默认必须输入一个参数x，即图片内容参数","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:16.72941Z","iopub.execute_input":"2022-04-15T08:40:16.729653Z","iopub.status.idle":"2022-04-15T08:40:17.012174Z","shell.execute_reply.started":"2022-04-15T08:40:16.729627Z","shell.execute_reply":"2022-04-15T08:40:17.011492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"style_img = d2l.Image.open(\"../input/imageshow/style3.jpg\")  # 读入风格图片\nprint(style_img)  # 可以看出内容图片和风格图片大小是不一样的\nd2l.plt.imshow(style_img)\n# 展示风格图片\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:17.013492Z","iopub.execute_input":"2022-04-15T08:40:17.01386Z","iopub.status.idle":"2022-04-15T08:40:17.385713Z","shell.execute_reply.started":"2022-04-15T08:40:17.013825Z","shell.execute_reply":"2022-04-15T08:40:17.385083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rgb_mean = torch.tensor([0.485, 0.456, 0.406])  # 定义RGB图像的三个通道的均值\nrgb_std = torch.tensor([0.229, 0.224, 0.225])  # 定义RGB图像的三个通道的方差\n\n# 定义预处理函数，输入两个参数：图像和需要重新定义的图像形状大小\ndef preprocess(img, image_shape):\n    # 使用torchvision的转换容器\n    #   1、重新裁剪图像大小（神经网络只能处理同样大小的图像）\n    #   2、转换成张量形式\n    #   3、按照之前定义的进行归一化，避免某些像素过于大或者过于小影响训练效果（梯度下降速度等）\n    transforms = torchvision.transforms.Compose(\n        [\n            torchvision.transforms.Resize(image_shape),\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize(mean=rgb_mean, std=rgb_std),\n        ]\n    )\n    # unsqueeze主要起到升维的作用，后续图像处理可以更好地进行批操作，在最低维增加一个0维轴\n    return transforms(img).unsqueeze(0)\n\n#定义后处理函数，输入一个参数：图像\ndef postprocess(img):\n    #将0维轴（即一个batch）的数据传入到对应的设备处理\n    img = img[0].to(rgb_std.device)\n    #将图像的CHW形式转换成卷积网络可以处理的HWC形式，并约束在方差和均值内，min=0，max=1，裁剪掉负数和大于1的值\n    img = torch.clamp(img.permute(1, 2, 0) * rgb_std + rgb_mean, 0, 1)\n    #将变回CHW形式的张量数据传递给PIL Image\n    return torchvision.transforms.ToPILImage()(img.permute(2, 0, 1))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:17.387744Z","iopub.execute_input":"2022-04-15T08:40:17.388161Z","iopub.status.idle":"2022-04-15T08:40:17.39807Z","shell.execute_reply.started":"2022-04-15T08:40:17.388127Z","shell.execute_reply":"2022-04-15T08:40:17.39727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#从torchvision的models库中导入VGG16模型，而且是已经经过参数训练过的\n#VGG19抽取[0,5,10,17,21]层作为风格层，24层作为内容层\npretrained_net = torchvision.models.vgg16(pretrained=True)\nstyle_layers, content_layers = [0,5,10,17,21], [24]","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:17.399714Z","iopub.execute_input":"2022-04-15T08:40:17.399959Z","iopub.status.idle":"2022-04-15T08:40:19.23544Z","shell.execute_reply.started":"2022-04-15T08:40:17.399926Z","shell.execute_reply":"2022-04-15T08:40:19.234678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#从torchvision的models库中导入VGG16模型，而且是已经经过参数训练过的\n#VGG16抽取[0,2,5,7,10]，28层作为内容层\npretrained_net = torchvision.models.vgg16(pretrained=True)\nstyle_layers, content_layers = [0,2,5,7,10], [28]","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:19.236639Z","iopub.execute_input":"2022-04-15T08:40:19.236882Z","iopub.status.idle":"2022-04-15T08:40:20.75434Z","shell.execute_reply.started":"2022-04-15T08:40:19.236849Z","shell.execute_reply":"2022-04-15T08:40:20.753596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#从torchvision的models库中导入VGG19模型，而且是已经经过参数训练过的\n#VGG19抽取0、5、10、19、28层作为风格层，25层作为内容层\npretrained_net = torchvision.models.vgg19(pretrained=True)\nstyle_layers, content_layers = [0,5,10,19,28], [25]","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:20.755652Z","iopub.execute_input":"2022-04-15T08:40:20.755911Z","iopub.status.idle":"2022-04-15T08:40:22.544868Z","shell.execute_reply.started":"2022-04-15T08:40:20.755877Z","shell.execute_reply":"2022-04-15T08:40:22.544129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pretrained_net)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.54633Z","iopub.execute_input":"2022-04-15T08:40:22.546991Z","iopub.status.idle":"2022-04-15T08:40:22.551529Z","shell.execute_reply.started":"2022-04-15T08:40:22.546953Z","shell.execute_reply":"2022-04-15T08:40:22.55087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#新建一个用于我们自己风格化处理的网络模型，只需要用到我们需要的几个层\n#只需要用到从输入层到最靠近输出层的内容层或样式层之间的所有层\n#可以简单调用torchvision的features模块组合成一个新的网络\n#作为实参的话，*相当于对tuple的解构，同样的**则是对dict的解构\nnet = nn.Sequential(\n    *[pretrained_net.features[i] for i in range(max(content_layers + style_layers) + 1)]\n)\n# print(net)\n# len(net)\n# net[0]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.552668Z","iopub.execute_input":"2022-04-15T08:40:22.553122Z","iopub.status.idle":"2022-04-15T08:40:22.559389Z","shell.execute_reply.started":"2022-04-15T08:40:22.553087Z","shell.execute_reply":"2022-04-15T08:40:22.558423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#提取特征函数，输入参数：图像的张量形式的量（即需要preprocess过），内容层序号，风格层序号\ndef extract_features(X, content_layers, style_layers):\n    #初始化内容和风格\n    contents = []\n    styles = []\n    for i in range(len(net)):\n        #调用net[i]层，输入图像X，返回结果重新给到X，即进行层net[i]的卷积or池化or全连接处理\n        X = net[i](X)\n        #下面判断是属于风格层还是内容层\n        if i in style_layers:\n            #风格styles列表的内容扩展添加上X\n            styles.append(X)\n        if i in content_layers:\n            #内容contents列表的内容扩展添加上X\n            contents.append(X)\n    return contents, styles\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.562508Z","iopub.execute_input":"2022-04-15T08:40:22.562991Z","iopub.status.idle":"2022-04-15T08:40:22.570823Z","shell.execute_reply.started":"2022-04-15T08:40:22.562931Z","shell.execute_reply":"2022-04-15T08:40:22.570158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 获取内容图像的内容特征，输入参数：图像形状大小，调用的设备device=\"cpu\" or \"gpu\"\ndef get_contents(image_shape, device):\n    # 图像的预处理，完成了裁剪、张量转换、归一化三个操作\n    content_X = preprocess(content_img, image_shape).to(device)\n    # 同样可以调用之前的提取特征函数进行特征的提取，这是最原始的内容图像的内容特征提取\n    # 这里只需要内容特征，不需要风格特征\n    contents_Y, _ = extract_features(content_X, content_layers, style_layers)\n    #X都是表示原始图像，Y表示进行了提取特征操作的图像\n    return content_X, contents_Y\n\n\n# 获取风格图像的风格特征，输入参数：图像形状大小，调用的设备device=\"cpu\" or \"gpu\"\ndef get_styles(image_shape, device):\n    # 图像的预处理，完成了裁剪、张量转换、归一化三个操作\n    style_X = preprocess(style_img, image_shape).to(device)\n    # 同样可以调用之前的提取特征函数进行特征的提取，这是最原始的风格图像的风格特征提取\n    # 这里只需要风格特征，不需要内容特征\n    _, styles_Y = extract_features(style_X, content_layers, style_layers)\n    return style_X, styles_Y\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.573354Z","iopub.execute_input":"2022-04-15T08:40:22.574473Z","iopub.status.idle":"2022-04-15T08:40:22.587948Z","shell.execute_reply.started":"2022-04-15T08:40:22.574434Z","shell.execute_reply":"2022-04-15T08:40:22.587238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def content_loss(Y_hat, Y):\n    # 我们从动态计算梯度的树中分离目标：\n    # 这是一个规定的值，而不是一个变量。\n    return torch.square(Y_hat - Y.detach()).mean()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.589379Z","iopub.execute_input":"2022-04-15T08:40:22.590015Z","iopub.status.idle":"2022-04-15T08:40:22.598676Z","shell.execute_reply.started":"2022-04-15T08:40:22.589979Z","shell.execute_reply":"2022-04-15T08:40:22.597971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义gram函数，输入为一个矩阵，默认为每个行向量之间的相关性\ndef gram(X):\n    # 计算通道个数C=X.shape[1]，索引为1的轴的维度\n    # 获取X的元素个数,X.numel()，再用个数除以通道个数得到HW的值，即列的个数\n    num_channels, n = X.shape[1], X.numel() // X.shape[1]\n    # 按照通道个数C和列的个数HW进行reshape\n    X = X.reshape((num_channels, n))\n    # 进行矩阵相乘算法，即Gram=XX^T\n    return torch.matmul(X, X.T) / (num_channels * n)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.600081Z","iopub.execute_input":"2022-04-15T08:40:22.601089Z","iopub.status.idle":"2022-04-15T08:40:22.612769Z","shell.execute_reply.started":"2022-04-15T08:40:22.601051Z","shell.execute_reply":"2022-04-15T08:40:22.612127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def style_loss(Y_hat, gram_Y):\n    return torch.square(gram(Y_hat) - gram_Y.detach()).mean()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.614184Z","iopub.execute_input":"2022-04-15T08:40:22.614803Z","iopub.status.idle":"2022-04-15T08:40:22.621638Z","shell.execute_reply.started":"2022-04-15T08:40:22.614768Z","shell.execute_reply":"2022-04-15T08:40:22.620875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tv_loss(Y_hat):\n    return 0.5 * (\n        # 这里的Tensor是BHWC格式的，通道在最后，所以按照减法应该是第3轴（索引2）的位置进行切片\n        torch.abs(Y_hat[:, :, 1:, :] - Y_hat[:, :, :-1, :]).mean()\n        + torch.abs(Y_hat[:, :, :, 1:] - Y_hat[:, :, :, :-1]).mean()\n    )\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.623086Z","iopub.execute_input":"2022-04-15T08:40:22.623708Z","iopub.status.idle":"2022-04-15T08:40:22.633986Z","shell.execute_reply.started":"2022-04-15T08:40:22.623648Z","shell.execute_reply":"2022-04-15T08:40:22.632857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#初始化三个损失的权重\ncontent_weight, style_weight, tv_weight = 1, 10000, 10\n\n#定义计算总权重损失的函数，输入参数：图像，\ndef compute_loss(X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram):\n    # 分别计算内容损失、样式损失和总变差损失\n    contents_l = [\n        content_loss(Y_hat, Y) * content_weight\n        for Y_hat, Y in zip(contents_Y_hat, contents_Y)\n    ]\n    styles_l = [\n        style_loss(Y_hat, Y) * style_weight\n        for Y_hat, Y in zip(styles_Y_hat, styles_Y_gram)\n    ]\n    tv_l = tv_loss(X) * tv_weight\n    # 对所有损失求和\n    l = sum(10 * styles_l + contents_l + [tv_l])\n    return contents_l, styles_l, tv_l, l\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.635595Z","iopub.execute_input":"2022-04-15T08:40:22.636724Z","iopub.status.idle":"2022-04-15T08:40:22.655138Z","shell.execute_reply.started":"2022-04-15T08:40:22.636687Z","shell.execute_reply":"2022-04-15T08:40:22.65433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#定义一个继承了父类nn.Module的子类SynthesizedImage\nclass SynthesizedImage(nn.Module):\n    #初始化类的函数，self是自身传入参数不用管，img_shape图像的大小，**表示字典变量\n    def __init__(self, img_shape, **kwargs):\n        super(SynthesizedImage, self).__init__(**kwargs)\n        #该类的weight的定义，含义是将一个固定不可训练的tensor转换成可以训练的类型parameter，\n        # 并将这个parameter绑定到这个module里面(net.parameter()中就有这个绑定的parameter，\n        # 所以在参数优化的时候可以进行优化的)，所以经过类型转换这个self.v变成了模型的一部分，\n        # 成为了模型中根据训练可以改动的参数了。\n        # 使用这个函数的目的也是想让某些变量在学习的过程中不断的修改其值以达到最优化。\n        #这里我们要优化的参数就是整个合成图像，那么大小也就是原始图像的大小，或者说输入图像的大小\n        self.weight = nn.Parameter(torch.rand(*img_shape))\n    \n    #前向传播只需要返回权重即可，这个权重是指合成图像的像素的权重\n    def forward(self):\n        return self.weight\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.658459Z","iopub.execute_input":"2022-04-15T08:40:22.659299Z","iopub.status.idle":"2022-04-15T08:40:22.669853Z","shell.execute_reply.started":"2022-04-15T08:40:22.659263Z","shell.execute_reply":"2022-04-15T08:40:22.669117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#定义初始化函数，输入参数：内容图像X，设备CPU or GPU，学习率，风格图像Y\ndef get_inits(X, device, lr, styles_Y):\n    #生成初始的合成图像实例，调用类SynthesizedImage产生\n    gen_img = SynthesizedImage(X.shape).to(device)\n    #使用copy_（）:\n    #解释说明：比如x4.copy_(x2),将x2的数据复制到x4,并且会\n    #修改计算图，使得反向传播自动计算梯度时，计算出x4的梯度后\n    #再继续前向计算x2的梯度。注意，复制完成之后，两者的值的改变互不影响，\n    #因为他们并不共享内存。\n    #实例gen_img的权重属性weight的数据data用内容图像X的值复制得到\n    gen_img.weight.data.copy_(X.data)\n    #训练优化使用Adam优化器，自适应动量优化器，输入参数为合成图像实例的参数方法，学习率由lr输入\n    trainer = torch.optim.Adam(gen_img.parameters(), lr=lr)\n    #多个风格特征提取得到的styles_Y分别进行Gram求解组成列表赋值给styles_Y_gram\n    styles_Y_gram = [gram(Y) for Y in styles_Y]\n    #返回生成的图像，风格特征的Gram列表，训练优化器\n    return gen_img(), styles_Y_gram, trainer\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.673853Z","iopub.execute_input":"2022-04-15T08:40:22.674601Z","iopub.status.idle":"2022-04-15T08:40:22.68595Z","shell.execute_reply.started":"2022-04-15T08:40:22.674566Z","shell.execute_reply":"2022-04-15T08:40:22.685282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#定义训练函数，参数输入：原始合成图像X（这里以原始内容图像content_X为基础），内容特征提取图像，风格特征提取图像，\n# 使用设备，初始学习率，迭代次数，学习率开始衰减的迭代次数\ndef train(X, contents_Y, styles_Y, device, lr, num_epochs, lr_decay_epoch):\n    #使用函数get_inits初始化得到：返回生成的图像，风格特征的Gram列表，训练优化器\n    X, styles_Y_gram, trainer = get_inits(X, device, lr, styles_Y)\n    #使用官方的torch.optim.lr_scheduler.StepLR方法确定训练的步骤，优化器选择，学习率开始衰减的迭代次数，衰减的gamma值\n    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_decay_epoch, 0.8)\n    #画图\n    animator = d2l.Animator(\n        xlabel=\"epoch\",\n        ylabel=\"loss\",\n        xlim=[10, num_epochs],\n        legend=[\"content\", \"style\", \"TV\"],\n        ncols=2,\n        figsize=(7*1.5, 2.5*1.5),\n    )\n\n    #开始迭代循环\n    for epoch in range(num_epochs):\n        #训练优化器梯度清零\n        trainer.zero_grad()\n        #提取特征，X是合成图像，会被迭代，然后重新输入训练，即每次迭代都将图像X输入到特征提取中，\n        # 计算特征，计算loss，优化参数，再得到新的x，再输入\n        contents_Y_hat, styles_Y_hat = extract_features(X, content_layers, style_layers)\n        contents_l, styles_l, tv_l, l = compute_loss(\n            X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram\n        )\n        #将总权重loss反向传播，计算参数的梯度\n        l.backward()\n        trainer.step()\n        scheduler.step()\n        #每10次输出一次后处理后的合成图像结果\n        if (epoch + 1) % 5 == 0:\n            animator.axes[1].imshow(postprocess(X))\n            animator.add(\n                epoch + 1, [float(sum(contents_l)), float(sum(styles_l)), float(tv_l)]\n            )\n    return X\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:40:22.690624Z","iopub.execute_input":"2022-04-15T08:40:22.691638Z","iopub.status.idle":"2022-04-15T08:40:22.708191Z","shell.execute_reply.started":"2022-04-15T08:40:22.6916Z","shell.execute_reply":"2022-04-15T08:40:22.707494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device, image_shape = d2l.try_gpu(), (600, 600)\nnet = net.to(device)\n#获取原始内容图像和获取了内容特征的图像，由于以内容图像为基础的合成图像，所以需要保留content_X\ncontent_X, contents_Y = get_contents(image_shape, device)\n#获取风格特征提取后的图像，省略了原始的风格图像style_X\n_, styles_Y = get_styles(image_shape, device)\n#进行训练，输入原始内容图像作为初次合成图像，内容特征提取图像，风格特征提取图像，\n# 使用设备，初始学习率0.3，迭代次数500，学习率开始衰减的迭代次数50\noutput = train(content_X, contents_Y, styles_Y, device, 0.3, 500, 50)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-15T08:45:42.315591Z","iopub.execute_input":"2022-04-15T08:45:42.31585Z","iopub.status.idle":"2022-04-15T08:49:45.124651Z","shell.execute_reply.started":"2022-04-15T08:45:42.315822Z","shell.execute_reply":"2022-04-15T08:49:45.123957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}